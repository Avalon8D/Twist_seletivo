{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  jQuery(document).ready(function($) {  \n",
    "  \n",
    "  $(window).on('load', function(){\n",
    "    $('#preloader').fadeOut('slow',function(){$(this).remove();});\n",
    "  });\n",
    "  \n",
    "  });\n",
    "</script>\n",
    "\n",
    "<style type=\"text/css\">\n",
    "  div#preloader { position: fixed; \n",
    "      left: 0; \n",
    "      top: 0; \n",
    "      z-index: 999; \n",
    "      width: 100%; \n",
    "      height: 100%; \n",
    "      overflow: visible; \n",
    "      background: #fff url('http://preloaders.net/preloaders/720/Moving%20line.gif') no-repeat center center; \n",
    "  }\n",
    "\n",
    "</style>\n",
    "\n",
    "<div id=\"preloader\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  } \n",
    "  \n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false; \n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import sys\n",
    "from scipy import stats\n",
    "\n",
    "from subprocess import run\n",
    "\n",
    "escaper_bash = str.maketrans({\"(\":  r\"\\(\", \")\":  r\"\\)\", \" \":  r\"\\ \", \"[\":  r\"\\[\", \"]\":  r\"\\]\", \"\\\\\": r\"\\\\\", \n",
    "                               \"^\":  r\"\\^\", \"$\":  r\"\\$\", \"*\":  r\"\\*\", \",\":  r\"\\,\", \"{\":  r\"\\{\", \"}\":  r\"\\}\",\n",
    "                               \"&\": r\"\\&\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction as f_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.naive_bayes as n_bayes\n",
    "import sklearn.svm as svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import builtins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de emails em span e não span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\quad$ Primeiro, carrega-se os dados em tabelas, via o pacote pandas\n",
    "\n",
    " $\\quad$ Uma inspeção aos arquivos de dados levou a concluir que carregá-los como tabelas facilitaria sua utilização e indexação durante a mineração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pasta com os data_sets enviados por email\n",
    "tables_path = '/home/avalon/Code/Twist_seletivo/'\n",
    "train_path = tables_path + 'Data_Train.csv'\n",
    "test_path = tables_path + 'Data_Test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\quad$ As tabelas foram concatenadas e devidamente indexadas. Isso pois a classificação será feita sobre os dados no formato td-idf, portanto, por conveniência, a conversão para esse será feita sobre todos os dados de uma só vez. Assim, o universo de palavras fica estabelecido e a utilização dos pacotes mais direta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_data_table = pd.concat ({'train': pd.read_csv (train_path, index_col='ID').sort_index (), \n",
    "                               'test': pd.read_csv (test_path, index_col='ID').sort_index ()}).sort_index ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whole_data_table.loc (axis=0)['train', whole_data_table.loc['train'].index[:10], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whole_data_table.loc (axis=0)['test', whole_data_table.loc['test'].index[:10], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\quad$ Há 'nan's na tabela para os dados de teste como place-holders pois não há classificação destes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toma-se stop words fornecidos pelo módulo NLTK para a língua portuguesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt_stop = set (stopwords.words ('portuguese'))\n",
    "count_data = f_e.text.CountVectorizer (stop_words=pt_stop) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converte-se os dados para o formato tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_data = count_data.fit_transform (whole_data_table['Message'].as_matrix ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separa-se então dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assume que o label 'test' vem antes de 'train'\n",
    "test_range = (0, whole_data_table.loc['test'].shape[0])\n",
    "train_range = (test_range[1], test_range[1] + whole_data_table.loc['train'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = whole_data[train_range[0]:train_range[1]]\n",
    "train_targets = whole_data_table['SPAM'][train_range[0]:train_range[1]].astype (float)\n",
    "test_data = whole_data[test_range[0]:test_range[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizar-se-á o método de classificação naive bayes, versão multinomial, para classificação do texto, disponibilizado pelo módulo sklearn\n",
    "\n",
    "### Todavia, este medo possui um hiperparâmetro, $\\alpha$, dito de suavização, que precisa ser escolhido\n",
    "### Para tal, Cross Validation num grid de parâmetros será efetuado afim de melhor selecionar o melhor parâmetro. Isto é, o melhor entre as pontuações médias em cada subconjunto dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid para o parâmetro de suavização, feito em escala log\n",
    "# a escolha das bordas do grid foi feita em vista da significância do parâmetro ao modelo\n",
    "# poderia ser tomado menor, a escolha foi conservadora\n",
    "grid_len = 100\n",
    "# grid de parâmetros de suavização\n",
    "smoothing_params = logspace (-1, log10 (train_data.shape[0]), num=grid_len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multn_bayes_models = {alpha: [n_bayes.MultinomialNB (alpha)] for alpha in smoothing_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O pacote sklearn possui um módulo para tal, capaz de realizar o processo, isso para diversas funções de pontuação\n",
    "\n",
    " $\\quad$ Assim sendo, soluciona-se as pontuações, mais usuais, abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list = ['f1', 'precision', 'recall']\n",
    "scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Quantidade de classes para Cross V.\n",
    "split_count = 10\n",
    "score_names = [score_kind + '_macro' for score_kind in scores_list]\n",
    "\n",
    "for alpha in multn_bayes_models:\n",
    "    \n",
    "    multn_bayes_models[alpha].append (cross_validate (multn_bayes_models[alpha][0], train_data, train_targets, \n",
    "                                                      scoring=['f1_macro', 'precision_macro', 'recall_macro'], cv=split_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\quad$ Avalia-se os melhores parâmetros para cada pontuação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_bests = {}\n",
    "\n",
    "for score_kind in scores_list:\n",
    "    cl_scores = array ([multn_bayes_models[alpha][1]\n",
    "                        ['test_' + score_kind + '_macro'].mean ()\n",
    "                        for alpha in smoothing_params])\n",
    "    \n",
    "    alpha_bests[score_kind] = [smoothing_params[cl_scores.argmax ()], cl_scores.max ()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_bests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $\\quad$ Fita-se os modelos baseado nas melhores pontuações para cada potuação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_n_bayes = {score_kind: n_bayes.MultinomialNB (alpha_bests[score_kind][0]).fit (train_data, train_targets)\n",
    "                 for score_kind in scores_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizada escolhidos os hiperparâmetros e realizada a classificação, segue a performa-se global destes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score_kind in scores_list:\n",
    "    train_predict = multi_n_bayes[score_kind].predict (train_data)\n",
    "    \n",
    "    print ('Scores for ' + score_kind + ' score Cross V.\\n')\n",
    "    print (metrics.classification_report (train_targets, train_predict, target_names=['Spam', 'NoSpam']))\n",
    "    print ('\\nRespective Confusion Matrix, or ROC\\n')\n",
    "    print (metrics.confusion_matrix (train_targets, train_predict))\n",
    "    print ('\\n---\\\\\\\\---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como todos os resultados foram similares e os parâmetros próximos, toma-se um deles para a classificação no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_data_table['SPAM-pred'] = array (multi_n_bayes['f1'].predict (whole_data), dtype=bool, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whole_data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_data_table.to_csv (tables_path + 'Data_stack_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resta, apenas, a performace no conjunto de teste\n",
    "    \n",
    " $\\quad$ A variável test_targets deve conter os targets para a classificação do conjunto de teste. Para isso, basta apenas carregar a tabela do conjunto de testes com a coluna de 'Spam' devidamente preenchida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predict = whole_data_table['SPAM-pred']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carrege aqui o vetor de classificação do conjunto de teste\n",
    "test_targets = whole_data_table['SPAM']['test'].astype (float) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performace no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Scores for ' + score_kind + ' score Cross V.\\n')\n",
    "print (metrics.classification_report (test_targets, test_predict, target_names=['Spam', 'NoSpam']))\n",
    "print ('\\nRespective Confusion Matrix, or ROC\\n')\n",
    "print (metrics.confusion_matrix (test_targets, test_predict))\n",
    "print ('\\n---\\\\\\\\---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obrigado pela atenção.\n",
    "P.A.S."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
